<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="In this work, we propose large dataset of 6,000+ video with subjective scores.">
  <meta property="og:title" content="LCVQAD: Large Compression Video Quality Assessment Dataset"/>
  <meta property="og:description" content="In this work, we propose large dataset of 6,000+ video with subjective scores."/>
  <meta property="og:url" content="TODO"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/favicon.ico" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="LCVQAD: Large Compression Video Quality Assessment Dataset">
  <meta name="twitter:description" content="In this work, we propose large dataset of 6,000+ video with subjective scores.">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/favicon.ico">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="dataset, video quality assessment, subjective study">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>LCVQAD: Large Compression Video Quality Assessment Dataset</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">LCVQAD: Large Compression Video Quality Assessment Dataset</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="TODO FIRST AUTHOR PERSONAL LINK" 
                  target="_blank">Aleksandr Gushchin</a><sup>1,2,3</sup>,
              </span>
              <span class="author-block">
                  <a href="TODO SECOND AUTHOR PERSONAL LINK" 
                    target="_blank">Maxim Smirnov</a><sup>4</sup>,
              </span>
              <span class="author-block">
                  <a href="TODO SECOND AUTHOR PERSONAL LINK" 
                    target="_blank">Anastasia Antsiferova</a><sup>2,3</sup>,
              </span>
              <span class="author-block">
                  <a href="TODO SECOND AUTHOR PERSONAL LINK" 
                    target="_blank">Dmitriy Vatolin</a><sup>1,2,3</sup>,
              </span>
            </div>

            <div class="is-size-5 publication-authors">
                <span class="author-block">
                    <sup>1</sup>
                    Lomonosov Moscow State University
                    <br>
                    <sup>2</sup>
                    ISP RAS Research Center for Trusted
                    Artificial Intelligence
                    <br>
                    <sup>3</sup>
                    MSU Institute for Artificial Intelligence
                    <br>
                    <sup>4</sup>
                    Yandex
                    <br>
                </span>
                <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
            </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/TODO <ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/TODO YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/TODO <ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/dataset_preview.webm"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Samples of our dataset. 
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Description</h2>
        <div class="content has-text-justified">
          <p>
            LCVQAD is the novel large dataset providing unrestricted access to a diverse collection of 6000+ compressed video streams generated with 40+ modern codecs and encoding presets. The dataset is featuring a variety of real‑world content and backed by crowdsourced subjective quality scores from Subjectify.us, it offers a reliable foundation for evaluating and advancing video‑quality assessment methods. 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Key features -->
<section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <div class="content has-text-justified">
                    <h2 class="title is-3">Key features</h2>
                    <p>
                        LCVQAD is <b>open-source</b> dataset with:
                        <ul>
                          <li>40+ different video codecs</li>
                          <li>5 compression standards (H.264/AVC, H.265/HEVC, H.266/VVC, AV1, VP9)</li>
                          <li>6,000+ compressed streams</li>
                          <li>2M+ subjective score</li>
                          <li>20,000+ subjective assessors</li>
                          <li>Various content, including UGC and screnn content</li>
                        </ul>
                    </p>
                </div>
            </div>
        </div>
    </div>
</section>


<!-- Videos -->
<section class="section hero is-light">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <div class="content has-text-justified">
                    <h2 class="title is-3">Videos</h2>
                    <p>
                      To gather source videos we parse High‐quality, openly licensed Full HD clips from Vimeo video service and clasterize 1,000,000+ videos to sample 50 of them. Sampled videos were first transcoded to a uniform YUV 4:2:0 format. Each reference video was then encoded with a suite of modern codecs (AVC/H.264, HEVC/H.265, AV1, VVC/H.266) using multiple presets and bitrate levels, yielding a broad spectrum of compressed streams for subjective quality evaluation.
                    </p>
                </div>
                <img src="static/images/selection.png">
                <!-- <h2 class="subtitle has-text-centered"> -->
                <br>
                Distribution of SI/TI characteristics and clusters during source videos sampling.
                <!-- </h2> -->
            </div>
        </div>
    </div>
</section>


<!-- Subjective scores -->
<section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <div class="content has-text-justified">
                    <h2 class="title is-3">Subjective study</h2>
                    <p>
                      To obtain high-quality subjective score for each video in LCVQAD, we employed two consecutive subjective studies. During the first one, we performed pairwise comparisons for each reference video. This way, obtained pairwise scores do not consider content of the video, which could potentially distort the resulting scores. For the second subjective study, we sampled three videos from each group to assess their MOS values. After that we use MAP to merge these two types of subjective score, projecting them onto single scale. More detailes can be seen in the paper.
                    </p>
                </div>
            </div>
        </div>
    </div>
</section>


<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Examples</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/samples/1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/samples/2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/samples/3.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/samples/4.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/samples/5.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video carousel -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
